{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8e7f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import expm, solve_discrete_lyapunov\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def build_ssm_approximation(kernel, delta_k, N):\n",
    "    \"\"\"\n",
    "    Построение SSM, аппроксимирующей ядро kernel на сетке с шагом delta_k\n",
    "    \"\"\"\n",
    "    # Дискретизация ядра\n",
    "    T = np.arange(0, 10*delta_k, delta_k)\n",
    "    Y = np.array([kernel(t, t) for t in T])\n",
    "    \n",
    "    # Реализация в пространстве состояний (фикс размерностей)\n",
    "    A = np.diag(np.exp(-np.linspace(0.1, 1.0, N)))\n",
    "    C = np.ones((1, N))  # (1, N)\n",
    "    \n",
    "    # Решение уравнения наблюдения (фикс размерности B)\n",
    "    P = solve_discrete_lyapunov(A, np.eye(N))\n",
    "    B = np.linalg.solve(P, C.T)  # (N, 1) вместо (1, N)\n",
    "    \n",
    "    # Подгонка под целевую функцию (фикс матричных операций)\n",
    "    Gamma = np.array([(C @ np.linalg.matrix_power(A, j) @ B).item() for j in range(len(T))])\n",
    "    beta = np.linalg.lstsq(Gamma.reshape(-1, 1), Y.reshape(-1, 1), rcond=None)[0]\n",
    "    \n",
    "    return A, B * beta, C\n",
    "\n",
    "def universal_approximator(attn_block, L, epsilon):\n",
    "    \"\"\"\n",
    "    Построение ансамбля SSM для аппроксимации блока внимания\n",
    "    \"\"\"\n",
    "    # Определение числа голов\n",
    "    K = int(np.ceil(1.0 / epsilon))\n",
    "    delta = L / K\n",
    "    \n",
    "    models = []\n",
    "    weights = []\n",
    "    \n",
    "    for k in range(1, K+1):\n",
    "        # Построение SSM для k-ой подпоследовательности\n",
    "        A, B, C = build_ssm_approximation(\n",
    "            lambda t, s: attn_block.kernel(t, s),\n",
    "            delta_k = k * delta,\n",
    "            N = int(np.ceil(np.log(1/epsilon))))\n",
    "        \n",
    "        models.append((A, B, C))\n",
    "        weights.append(1.0 / k)\n",
    "    \n",
    "    # Нормализация весов\n",
    "    weights = np.array(weights) / np.sum(weights)\n",
    "    \n",
    "    return models, weights, K\n",
    "\n",
    "def visualize_kernels(attn_block, models, weights, L, K):\n",
    "    \"\"\"\n",
    "    Визуализация сравнения ядер внимания и SSM-аппроксимации\n",
    "    \"\"\"\n",
    "    # Создание сетки\n",
    "    t = np.linspace(0, L, 100)\n",
    "    s = np.linspace(0, L, 100)\n",
    "    T, S = np.meshgrid(t, s)\n",
    "    \n",
    "    # Истинное ядро\n",
    "    true_kernel = np.vectorize(attn_block.kernel)(T, S)\n",
    "    \n",
    "    # Аппроксимированное ядро\n",
    "    approx_kernel = np.zeros_like(T)\n",
    "    for idx, (A, B, C) in enumerate(models):\n",
    "        for i in range(len(t)):\n",
    "            for j in range(len(s)):\n",
    "                delay = np.abs(t[i] - s[j])\n",
    "                steps = int(delay // (L / K))\n",
    "                if steps < 100:\n",
    "                    # Матричное умножение с правильными размерностями\n",
    "                    power = np.linalg.matrix_power(A, steps)\n",
    "                    approx_kernel[i, j] += weights[idx] * (C @ power @ B).item()\n",
    "    \n",
    "    # Разность\n",
    "    diff = np.abs(true_kernel - approx_kernel)\n",
    "    \n",
    "    # Визуализация\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    titles = [\n",
    "        \"Трансформер: Истинное ядро\",\n",
    "        f\"Mamba: Аппроксимация (K={K})\",\n",
    "        f\"Разность (MSE: {np.mean(diff**2):.2e})\"\n",
    "    ]\n",
    "    \n",
    "    for i, data in enumerate([true_kernel, approx_kernel, diff]):\n",
    "        im = axs[i].imshow(data, cmap='viridis' if i < 2 else 'plasma', \n",
    "                          origin='lower', extent=[0, L, 0, L])\n",
    "        axs[i].set_title(titles[i])\n",
    "        axs[i].set_xlabel(\"Позиция s\")\n",
    "        axs[i].set_ylabel(\"Позиция t\")\n",
    "        fig.colorbar(im, ax=axs[i])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"kernel_approx_K{K}.png\", dpi=120)\n",
    "    plt.close()\n",
    "    \n",
    "    return true_kernel, approx_kernel\n",
    "\n",
    "def plot_convergence(attn_block, L, max_K=20):\n",
    "    \"\"\"\n",
    "    Анализ сходимости при увеличении числа голов\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    K_values = range(1, max_K+1)\n",
    "    \n",
    "    for K in K_values:\n",
    "        _, approx_kernel = visualize_kernels(\n",
    "            attn_block,\n",
    "            *universal_approximator(attn_block, L, 1/K)[:2],\n",
    "            L, K\n",
    "        )\n",
    "        # Вычисление ошибки\n",
    "        diff = np.abs(attn_block.kernel(0.3*L, 0.7*L) - approx_kernel[int(30), int(70)])\n",
    "        errors.append(diff)\n",
    "    \n",
    "    # График\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(K_values, errors, 'o-', label=\"Эксперимент\")\n",
    "    plt.plot(K_values, 1/np.array(K_values), 'r--', label=\"Теория O(1/K)\")\n",
    "    plt.xlabel(\"Число голов (K)\")\n",
    "    plt.ylabel(\"Ошибка аппроксимации\")\n",
    "    plt.title(\"Сходимость к трансформеру\")\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"convergence.png\", dpi=120)\n",
    "    plt.close()\n",
    "    \n",
    "    return errors\n",
    "\n",
    "def visualize_head_responses(models, weights, L, K):\n",
    "    \"\"\"\n",
    "    Визуализация импульсных характеристик голов\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    for idx, (A, B, C) in enumerate(models):\n",
    "        # Импульсная характеристика\n",
    "        response = []\n",
    "        h = np.zeros((A.shape[0], 1))\n",
    "        impulse = np.zeros(100)\n",
    "        impulse[0] = 1.0\n",
    "        \n",
    "        for i in range(100):\n",
    "            h = A @ h + B * impulse[i]\n",
    "            response.append((C @ h).item())\n",
    "        \n",
    "        # График\n",
    "        plt.plot(response, lw=2, \n",
    "                label=f\"Голова {idx+1} (шаг={K/(idx+1):.1f}, вес={weights[idx]:.3f})\")\n",
    "    \n",
    "    plt.title(\"Импульсные характеристики SSM-голов\")\n",
    "    plt.xlabel(\"Временной шаг\")\n",
    "    plt.ylabel(\"Отклик\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(\"head_responses.png\", dpi=120)\n",
    "    plt.close()\n",
    "\n",
    "# Тестовый блок внимания\n",
    "class AttentionBlock:\n",
    "    def __init__(self, kernel_type='gaussian'):\n",
    "        self.kernel_type = kernel_type\n",
    "        \n",
    "    def kernel(self, t, s):\n",
    "        if self.kernel_type == 'gaussian':\n",
    "            return np.exp(-0.1*(t-s)**2)\n",
    "        elif self.kernel_type == 'laplace':\n",
    "            return np.exp(-0.2*np.abs(t-s))\n",
    "        else:  # constant\n",
    "            return 1.0 if np.abs(t-s) < 0.1*L else 0.0\n",
    "\n",
    "# Пример использования\n",
    "if __name__ == \"__main__\":\n",
    "    L = 100  # Длина последовательности\n",
    "    attn_block = AttentionBlock(kernel_type='gaussian')\n",
    "    \n",
    "    # Построение аппроксиматора\n",
    "    models, weights, K = universal_approximator(attn_block, L, 0.2)\n",
    "    \n",
    "    # Визуализация\n",
    "    visualize_kernels(attn_block, models, weights, L, K)\n",
    "    plot_convergence(attn_block, L)\n",
    "    visualize_head_responses(models, weights, L, K)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
